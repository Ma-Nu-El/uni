#+TITLE: Probabilidad y Estadística
#+SUBTITLE: Regresión
#+INCLUDE: "~/org/config/author-mfuica01.org"
#+INCLUDE: "~/org/config/config-spanish.org"
#+INCLUDE: "~/org/config/config.org"

* Índice :TOC_1:noexport:
- [[#introducción][Introducción]]
- [[#modelo-lineal][Modelo Lineal]]
- [[#notas-de-la-clase][Notas de la clase]]
- [[#otras-fuentes-y-herramientas][Otras fuentes y herramientas]]
- [[#consultas-al-profe][Consultas al profe]]
- [[#footnotes][Footnotes]]

* Introducción
** Representación visual
- [[https://latexdraw.com/linear-regression-in-latex-using-tikz/][Linear Regression in LaTeX using TikZ - TikZBlog]]
- [[https://tex.stackexchange.com/questions/119179/how-to-add-a-regression-line-to-randomly-generated-points-using-pgfplots-in-tikz][How to add a regression line to randomly generated points using pgfplots in Tikz? - TeX - LaTeX Stack Exchange]]
** Conceptos
*** Correlación (R) y autocorrelación
**** Coeficiente de correlación (aka =R= o =r=)
:PROPERTIES:
:ID:       60c50020-54c2-4610-993a-4bb60512b250
:END:
- Es el nivel de relación existente entre
  2 variables; se entiende como el porcentaje
  de datos que poseen una asociación
  directa o inversa.
- Interpretación:
  - "De cada 100 pares de datos, \(R \cdot 100 \)
    tienen el mismo comportamiento".

**** Correlación y calidad del modelo
:PROPERTIES:
:ID:       77f78879-51fa-4196-bdf0-15d43876b0a1
:END:

Una correlación = |1| /no/ es existe.
- Teóricamente sí, pero siempre hay errores.


\begin{align*}
  R < \vert{} 0.2 - 0.3 \vert{}
    &\iff \text{no hay relación.} \\
  \vert{} 0.4 \vert{} < R < \vert{} 0.6 \vert{}
    &\iff \text{relación baja.} \\
  \vert{} 0.6 \vert{} < R < \vert{} 0.8 \vert{}
    &\iff \text{relación media.} \\
  \vert{} 0.8 \vert{} < R < \vert{} 1.0 \vert{}
    &\iff \text{relación alta.}
\end{align*}



- Profe Carlos trabaja con R > |0.7|.

**** Autocorrelación
- La autocorrelación mide el nivel
  de [[id:60c50020-54c2-4610-993a-4bb60512b250][correlación]] entre dos instancias
  de la misma variable, separadas por
  un intervalo de tiempo o espacio.
- [[https://www.investopedia.com/terms/a/autocorrelation.asp][Autocorrelation Definition]]
- [[https://corporatefinanceinstitute.com/resources/knowledge/other/autocorrelation/][Autocorrelation - Overview, How It Works, and Tests]]
- Si existe autocorrelación, entonces
  sabiendo el valor actual de una variable,
  podemos predecir con cierta certeza el
  valor futuro o pasado de la misma variable.
- Ejemplo: si hoy llueve, entonces es más
  probable que mañana también llueva; diferente
  de que si hoy está despejado, entonces
  es menos probable que mañana llueva.
- La autocorrelación mide la relación entre
  el valor actual de una variable y sus
  valores pasados.
- "La autocorrelación o dependencia secuencial
  es una característica que consiste en que,
  elementos cercanos en el espacio o en el
  tiempo se parecen más entre sí que con
  respecto a elementos más lejanos,
  solamente por el hecho de estar cerca."

*** Determinación (R^2)
**** Coeficiente de determinación (R^{2})

- Porcentaje de variación de =Y= que es explicado
  por =X=.
- ¿Qué porcentaje de =X= puede explicar la
  varianza de =Y=?
- ¿O qué porcentaje de la varianza de =Y= puede
  ser explicado por =X=?

**** Coeficiente de determinación ajustado(R^{2}_{aj})

- Lo mismo que =R^2=, pero considera fallas
  ocasionadas por el tamaño de la muestra.

**** R^2 vs R^2_aj

- \(R^{2}_{aj} \leq R^{2}\)
- Si no hay problemas por el tamaño de la muestra,
  son iguales.
- Si hay problemas, \(R^{2}_{aj}\) tiende a
  ser menor.
- Ante una diferencia, hay que usar el ajustado.
- Hasta 4% de diferencia es aceptable, luego,
  se usa R2 ajustado.
- Si \(R^2\) > \(R^2_{aj}\)
  - Si no puedes aumentar el tamaño de la muestra,
    entonces trabaja con el ajustado.
- Se considera una diferencia entre
  R^2 y R^2_{aj} importante cuando es
  superior al 3-4% [fn:1].

*** Homocedasticidad
- [[https://stats.stackexchange.com/questions/406509/is-there-any-difference-between-heteroscedasticity-and-homoscedasticity][Is there any difference between heteroscedasticity and homoscedasticity? - Cross Validated]]
- [[https://www.scribbr.com/frequently-asked-questions/what-is-homoscedasticity/][What is homoscedasticity?]]


En cuanto a [[id:38d60dbe-8e28-4cb5-8c57-7113f4027986][modelos de regresión lineal simple]]:
- Se busca que la dispersión --- o cedasticidad ---,
  de los errores en una muestra, estén esparcidos
  de forma homogénea, cumpliendo con el
  [[id:806ba6ae-fb8c-47cb-9635-8433a4b40d80][supuesto de la normalidad de los errores]],
  de otra forma en realidad no estaríamos
  hablando de un modelo lineal.

*** Linealidad, co-linealidad y multi-co-linealidad
- Linealidad
  - Cuando existe una relación lineal entre
    2 variables.
- Co-lineal
  - Cuando 2 o más valores de una variable
    pertenecen a una recta.
- Multi-co-lineal
  - Cuando 2 o más variables independientes
    presentan [[id:60c50020-54c2-4610-993a-4bb60512b250][correlación]] lineal entre sí.
  - Si presentan una correlación fuerte,
    entonces en realidad una de ellas
    puede ser considerada dependiente
    de la otra, por lo que en realidad
    no son independientes, ergo, pueden
    ser consideradas independientes en la
    suposición inicial pero co-lineales
    entre si luego de realizar las pruebas de
    multicolinealidad.
  - Una consecuencia de la multicolinealidad
    es que no se puede distinguir cúales
    efectos son ocasionados por una variable
    independiente y cúales son ocasionados
    por otra.


- [[https://www.youtube.com/watch?v=G1WX5GiFSWQ][Multicollinearity (in Regression Analysis) - YouTube]]
** Calidad de la construcción vs calidad del modelo

- Un modelo bien construido procura cumplir la
  mayor cantidad de supuestos; por ejemplo,
  los [[id:806ba6ae-fb8c-47cb-9635-8433a4b40d80][supuestos]] del modelo lineal. Un mal modelo
  no cumple con muchos supuestos.
- Un modelo bueno tiene una alta [[id:77f78879-51fa-4196-bdf0-15d43876b0a1][correlación]].


A partir de esto se pueden tener 4 tipos de
modelos:
- Modelos buenos bien construidos.
- Modelos buenos mal construidos.
- Modelos malos bien construidos.
- Modelos malos mal construidos.


Condición de cálculo:
- n: tamaño de la muestra.
- k: número de parámetros.
- n > k

* Modelo Lineal
:PROPERTIES:
:ID:       38d60dbe-8e28-4cb5-8c57-7113f4027986
:END:
** Pasos para un modelo bien construido
*** 1 Calidad del dato
- Análisis de valores atípicos
*** 2 Construcción del modelo
- Se le entrega la información al programa y
  este lo construye.
  - Ejemplo en R: [[id:db95037a-1538-4991-92f7-5b0170f5baa0][Paso 2: Construcción del modelo]].
*** 3 Análisis de supuestos
- [[id:806ba6ae-fb8c-47cb-9635-8433a4b40d80][Supuestos]]
*** 4 Evaluar el modelo
1) Correlacion: R
   : pearson
   - todas continuas
   : spearman
   - una discreta u ordinal
     - (generalmente la independiente)
   : \Tau de Kendall
   - dos discretas u ordinales
   : V de Cramer
   - ordinales
   : \Chi -cuadrado
   - nominal
2) Varianza
   : anova(mod1)
3) R^2 y R^2_{ajustado}
   : summary(mod1)
4) Evaluar parámetros



- \beta_{i} = 0 \iff significa que se debe construir
  un nuevo modelo.

** Supuestos para la realización de un modelo RLM (RLS)
:PROPERTIES:
:ID:       806ba6ae-fb8c-47cb-9635-8433a4b40d80
:END:
- u es el error.


1. E(u) = \bar u = 0.
   - El promedio de los errores es cero.
2. V(u) es mínima.
   - La varianza de los errores es mínima.
3. u \sim N(0,\sigma^{2}_{u})
   - Los errores se comportan normalmente.
4. Los u's son independientes.
   - Los errores son independientes entre si.
5. No auto-correlación.
6. Homocedasticidad.
   - Los errores están dispersos de
     forma homogénea.
7. No multicolinealidad.
   - Si no es cero, entonces tengo variables
     independientes que están en función
     de otras variables independientes.

** R script para los supuestos
*** Preámbulo: Importación de los datos
:  datos <- origen_de_los_datos
:  y <- datos$variable_dependiente
:  x <- datos$variable_independiente

*** Paso 1: Análisis de valores atípicos
:  descripY(datos,y)

*** Paso 2: Construcción del modelo
:PROPERTIES:
:ID:       db95037a-1538-4991-92f7-5b0170f5baa0
:END:

:  mod1 <- lm(y~x,datos)
:  plot(x,y)
:  plot(mod1) # el (Residuals vs Leverage)

*** Paso 3: Analisis de supuestos
**** 1 Promedio de los errores = 0

: mean(mod1$residuals)

**** 2 Varianza de los errores minima:
- Justificación de [[id:a08d2fa9-4dfc-4f3e-8280-1b67b760e40b][Método de Mínimos Cuadrados]].
**** 3 Errores con comportamiento normal
: shapiro.test(mod1$residuals)
- Todos los test de la libreria =nortest=.
- =HO= es que los errores se comportan normalmente,
  por lo que en este caso, para cumplir el
  supuesto nos sirve un =p-value= menor a \alpha.

**** 4 Independencia de los errores:
: plot(mod1$fitted.values,mod1$residuals)
- o el gráfico 1 del =plot(mod1)=.
  - recuerda apretar ENTER en la consola.
- Si hay un patrón en el gráfico, entonces
  menos independientes son los errores.
  Mientras menos datos, más probable
  encontrar un patrón que no
  tiene verdadero sentido.

**** 5 Autocorrelación = 0
: dwtest(mod1)
- como en supuesto 3, para este
  caso libreria =AER=.
- =HO=:

**** 6 Homocesdasticidad de los errores
: bptest(mod1)
- =H0=: Errores homocedasticos.
  - Para cumplir con el supuesto,
    nos sirve un =p-value=.
- =H1=: Errores heterocedasticos.


- Requiere de un =B0=, por lo que si
  eliminamos el =B0= podemos ocupar
  el gráfico 3 del =plot(mod1)=.
  =Scale-Location=.
- Cuando el gráfico se abre, es probable
  la heterocedasticidad, si se mantiene
  en una manga, entonces es homocedastico,
  independiente de la forma de la mango.
  Idealmente una manga con diámetro constante.
  Aunque no se abra, si el diámetro aumenta
  en algún momento, es probable la
  heterocedasticidad.

**** 7 Multicolinealidad:
- Como estamos trabajando con una variable,
  este punto no aplica.
*** Paso 4: Evaluar modelo
**** =R= de correlacion

: cor.test(y,x,method="pearson")

**** Varianza

: anova(mod1)

| =Pr(F)=p-value=                  | H0: modelo no existe. |
| =meansq(residuals)= = sigma2_err | H1: modelo existe.    |

**** Determinación (R^{2} y R^{2}_{aj}

: summary(mod1)
- =Intercept= es la columna del =B0=.
- =x= es la columna del =B1=.
- =Pr(t)= es el =p-value= de cada uno donde
  el =H0= es =B_i= = =0= con =i=(0,1)=.
- Si =B0=0= entonces se propone un modelo nuevo.
- Si =B1=0= entonces la variable independiente no
  explica el comportamiento de la dependiente.

** Método de Mínimos Cuadrados Ordinarios (MMCO)
:PROPERTIES:
:ID:       a08d2fa9-4dfc-4f3e-8280-1b67b760e40b
:END:
- ¿Relación con varianza y el supuesto 2?
- El método de mínimos cuadrados se utiliza
  para obtener una recta que aproxime
  el comportamiento de pares de datos.
  Por lo tanto, al estar obteniendo esta
  recta con los pasos enseñados por el
  profesor, estamos implícitamente
  aplicando el método de mínimos cuadrados y,
  por lo tanto, asegurando el [[id:806ba6ae-fb8c-47cb-9635-8433a4b40d80][supuesto]] 2.
- [[https://www.youtube.com/watch?v=gUdU6BgnJ2c][Método de Mínimos cuadrados - YouTube]]
- [[https://www.youtube.com/watch?v=k964_uNn3l0][Regresión Lineal y Mínimos Cuadrados Ordinarios | DotCSV - YouTube]]

** Plots su interpretación
:PROPERTIES:
:ID:       4fbef882-7269-4f63-b12f-8dc05d47cb2a
:END:
*** Residuals vs Fitted
*** Normal Q-Q
- Comportamiento normal de los pares.
*** Scale-Location

: bptest(mod1)
- Si =mod1= es un modelo lineal, entonces el
  gráfico =Scale-Location= describe la
  homocedasticidad de los errores.

*** Residuals vs Leverage
** Tests y sus hipótesis
:PROPERTIES:
:ID:       a0997225-c107-48fa-90a7-c26f46c71414
:END:
*** paso 3:
**** supuesto 3: =shapiro.test=
: shapiro.test(mod1$residuals)
- =H0= :
- =H1= :
Por lo tanto, si:
- =p-value= \geq \alpha
  - entonces
- =p-value= < \alpha.
  - entonces
**** supuesto 5: =dwtest=
: dwtest(mod1)
- =H0= :
- =H1= :
Por lo tanto, si:
- =p-value= \geq \alpha
  - entonces
- =p-value= < \alpha.
  - entonces
**** supuesto 6: bptest
- =H0= :
- =H1= :
Por lo tanto, si:
- =p-value= \geq \alpha
  - entonces
- =p-value= < \alpha.
  - entonces
*** paso 4:
**** correlación R: cor.test
: cor.test(y,x,method="pearson")
- =H0= : =R=0=
- =H1= : =R!=0=
Por lo tanto, si:
- =p-value= \geq \alpha
  - entonces
- =p-value= < \alpha.
  - entonces
**** varianza: anova
- =H0= :
- =H1= :
Por lo tanto, si:
- =p-value= \geq \alpha
  - entonces
- =p-value= < \alpha.
  - entonces
**** =R^2= y =R^{2}_{aj}
: summary(mod1)
- =H0= :
- =H1= :
Por lo tanto, si:
- =p-value= \geq \alpha
  - entonces
- =p-value= < \alpha.
  - entonces

* Notas de la clase
** Scripts usados
*** para la materia

- =SCRIPT_A01_4_descripY.r=
- =SCRIPT P01 Analisis de Distribucion.r=
- =SCRIPT P02 Analisis de Distribucion.r=
- =SCRIPT REGRESION MULTIPLE.r=

*** ejemplos en clases
**** [2022-06-14 Tue]
- datos<-PSU_diagnostico_01

#+begin_example R
source ("~/Downloads/uni/2022-1/proba/scripts-r/SCRIPT_A01_4_descripY.R")
source ("~/Downloads/uni/2022-1/proba/scripts-r/SCRIPT REGRESION MULTIPLE.r")

# eliminamos los que no rindieron la prueba
datos<-datos[datos$rend1>0,]

# Analisis supuesto colinealidad
chart.Correlation(datos)
# se recomienda identificar la variable sensible: "la que
# no tengo que tocar"

# elimino las variables colineales
datos<-dplyr::select(PSU_diagnostico_01,-PEM,-HIST,-PROMPSU,-PSUPOND,-LENG,-CS)
# tienen que estar en el mismo orden

model01<-lm(datos$rend1~.,data=datos)
vif(model01) # el output: ojala 1, o lo mas cercano a 1
summary(model01)

# Analisis supuestos
# S1
# mean(model01$residuals)

# S2
# Metodo de minimos cuadrados

# S3 errores se comportan normal
# HO: los datos se comportan normal
# shapiro.test(model01$residuals)
# andersen
# cramer
# lilly
# pearson
# ks
# todos lo de la libreria nortest

# S4 errores independientes
# plot(model01$residuals)

# S5 no autocorrelación
# HO: no existe autocorrelación
# Test DurbinWatson
# dwtest(model01)

# S6 Homocedasticidad
# HO: varianzas iguales
# test BreuschPagan
# bptest(model01)

# S7 No multicolinealidad
# HO: no hay variables colineales
#+end_example

**** [2022-06-28 Tue]

- Datos:
: "reg-2 variables ind.xlsx"
- Script de referencia:
: "SCRIPT REG LINEAL SIMPLE v01-05.r"

**** [2022-07-01 Fri]

- Pasos para un modelo bien construido.


1) Calidad del dato:
   - =IncendiosForestales= importado desde excel:
   #+begin_example R
   datos <- IncendiosForestales
   y <- datos$Ind_Combustibilidad
   x <- datos$temp
   #+end_example

   - primera visualización en busca de datos atípicos
   #+begin_example R
   descripY(datos,y)
   #+end_example

2) Construcción un modelo

   #+begin_example R
   mod1 <- lm(y~x,datos)
   #+end_example
   - gráfico 4 (Residuals vs Leverage).
     - (en el word pego estos dos).
   #+begin_example R
   plot(x,y)
   plot(mod1) # el (Residuals vs Leverage)
   #+end_example

3) Supuestos:
   1) Promedio de los errores = 0

      #+begin_example R
      mean(mod1$residuals)
      #+end_example

   2) Varianza de los errores minima:
      - Justificación de Método de Mínimos
        Cuadrados.
   3) Los errores se comportan normalmente:
      #+begin_example R
      shapiro.test(mod1$residuals)
      #+end_example
      - todos los test de la libreria =nortest=.

   4) Independencia de los errores:
      #+begin_example R
      plot(mod1$fitted.values,mod1$residuals)
      #+end_example
      - o el gráfico 1 del =plot(mod1)=.
        - recuerda apretar ENTER en la consola.
      - Si hay un patrón en el gráfico, entonces
        menos independientes son los errores.
        Mientras menos datos, más probable
        encontrar un patrón que no
        tiene verdadero sentido.

   5) Autocorrelacion=0:
      #+begin_example R
      dwtest(mod1)
      #+end_example
      - como en supuesto 3, para este
        caso libreria =AER=.

   6) Homocesdasticidad
      #+begin_example R
      bptest(mod1)
      #+end_example
      - H0: homocedastico
      - H1: heterocedastico

      - Requiere de un B0, por lo que si
        eliminamos el B0 podemos ocupar
        el gráfico 3 del =plot(mod1)=.
        =Scale-Location=.
      - Cuando el gráfico se abre, es probable
        la heterocedasticidad, si se mantiene
        en una manga, entonces es homocedastico,
        independiente de la forma de la mango.
        Idealmente una manga con diámetro constante.
        Aunque no se abra, si el diámetro aumenta
        en algún momento, es probable la
        heterocedasticidad.

   7) Multicolinealidad:
      - Como estamos trabajando con una variable,
        este punto no aplica.
4) Evaluar modelo
   - R:
   #+begin_example R
   cor.test(y,x,method="pearson")
   #+end_example
   - Modelo
   #+begin_example R
   anova(mod1)
   #+end_example
     | =Pr(F)=p-value=                  | H0: modelo no existe. |
     | =meansq(residuals)= = sigma2_err | H1: modelo existe.    |
   - Reporte
   #+begin_example R
   summary(mod1)
   #+end_example
   - intercept es la columna del =B0=.
   - =x= es la columna del =B1=.
   - =Pr(t)= es el =p-value= de cada uno donde
     el =H0= es =B_i= = =0= con =i=(0,1)=.
   - Si =B0=0= entonces se propone un modelo nuevo.
   - Si =B1=0= entonces la variable independiente no
     explica el comportamiento de la dependiente.

** [2022-06-17 Fri]
*** Independencia de errores
- [2022-06-17 Fri 09:25]
- Contexto: supuesto 4: independencia de
  los errores.


- Aumenta el Ingreso \implies Aumenta el gasto.



- Si el procedimiento de muestreo se hizo
  correctamente, entonces no debería
  haber relación entre los errores,
  por lo que cualquier supuesto patrón
  existente sería una relación espúrica.
- Cuando existen pocos datos, es fácil encontrar
  patrones, pero puede que no tengan sentido.
- Ante la presencia de más datos, encontrar un
  patrón se hace más difícil; encontrar un
  patrón en ese caso, es más probable que
  tenga una explicación lógica.


- [2022-06-17 Fri 09:34]
  - Auto-Correlación:
    - La variable tiempo puede no estar explícita,
      pero sí explícita.

*** Cantidad de estrellas y significancia

- 1: \alpha < 0.001
- 2: \alpha < 0.01
- 3: \alpha < 0.05
- 0: \alpha < 1


- Mientras más estrellas, "más menor" que \alpha.


: Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

*** Qué tipo de variable?
- La escala de medida determina el tipo de variable.
  - "Rojo".
    - Puede ser un color, estado de ánimo, nota,
      o cualquier cosa.
    - La unidad de medida determina a qué
      tipo de variable nos estamos refiriendo.

*** Anova
*** Qué es el residual?
- \(u = Y - \cap Y\)

** [2022-06-22 Wed]
- Qué significa B0 igual a 0?
  - Que hay que hacer otro modelo ajustado.
- [2022-06-22 Wed 12:00]
  - "Si el S de la media de los errores no se cumple
    y el supuesto de normalidad tampoco,
    entonces olvídate del modelo".
- [2022-06-22 Wed 12:10]
  - "De los modelos presentes, el menos malo es..."
- [2022-06-22 Wed 12:25]
  - Ejemplo 11.3 del libro en campus.
- [2022-06-22 Wed 12:33]
  - "Para un modelo simple, el Beta 1 tiene que
    tener el mismo signo que el R."
** [2022-07-01 Fri]
- Lunes, RA1002.

** [2022-07-04 Mon]
:CLOCKBOOK:
CLOCK: [2022-07-04 Mon 11:09]--[2022-07-04 Mon 11:34] =>  0:25
:END:

- Dados los gráficos, analice los pasos
  para la construcción de un modelo lineal simple.
- M275-1 Clase 04 de julio 2022.
  - Dos hojas más de ejercicios.

*** Paso 1: Análisis de valores atípicos
*** Paso 2: Crear modelo
*** Paso 3: Análisis de supuestos
*** Paso 4: Evaluar modelo
* Otras fuentes y herramientas
** Simulaciones
- phet
  - [[https://phet.colorado.edu/sims/html/curve-fitting/latest/curve-fitting_en.html][Curve Fitting]]
** Libros

- En campus hay 2 muy buenos.
- Unidad 11: Regresión lineal simple y correlación.
  - pag 389.

* Consultas al profe
- [[id:4fbef882-7269-4f63-b12f-8dc05d47cb2a][Plots su interpretación]]
- [[id:a0997225-c107-48fa-90a7-c26f46c71414][Tests y sus hipótesis]]


- ¿Los [[id:806ba6ae-fb8c-47cb-9635-8433a4b40d80][supuestos]] 4 y 5 hacen referencia a la
  correlación --- o "autocorrelación" ---
  de los errores y autocorrelación
  de la variable independiente respectivamente?

* Footnotes

[fn:1]
[2022-07-04 Mon 11:41] "Casi que a gusto del
consumidor". CJG.
# Local Variables:
# ispell-local-dictionary: "espanol"
# End:

#  LocalWords:  curtosis homocedasticidad autocorrelación espúrica cedasticidad
#  LocalWords:  script
